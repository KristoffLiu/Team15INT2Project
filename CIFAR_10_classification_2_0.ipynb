{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10 classification 2.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ0wBuXCswlo"
      },
      "source": [
        "# Downloading and preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyR4qrFMswlq"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1pRAKp0swls"
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = datasets.cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cA0nUAVswlt"
      },
      "source": [
        "train_x, test_x = train_x / 255.0, test_x / 255.0 #changes pixel values between 0 and 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr-igcfXswlt"
      },
      "source": [
        "# Improving the Basic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnVT4on7swlu",
        "outputId": "320c7374-8265-4f9e-e4ae-fb24b772ee35"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32,32,3)))#creates layers for a 2d array of pixels\n",
        "model.add(layers.Conv2D(32,(3,3), padding='same', activation='relu'))\n",
        "#model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2))) #pooling helps detect features in an image, max pooling finds largest value\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv2D(64,(3,3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(64,(3,3), padding='same', activation='relu'))\n",
        "#model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3), padding='same', activation='relu'))\n",
        "model.add(layers.Conv2D(128,(3,3), padding='same', activation='relu'))\n",
        "#model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation = 'relu'))#regularisation of data\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                131136    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 419,050\n",
            "Trainable params: 418,922\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWko6DFAswlw"
      },
      "source": [
        "# Running, training, and evaluating data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlVi9t-eswlw",
        "outputId": "e2ed757a-3e59-4bdc-dd9d-a4ba46cddcbd"
      },
      "source": [
        "model.compile(optimizer='RMSprop',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "#adam optimisatin is a slightly better gradient decent for computer vision\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "progress = model.fit(train_x, train_y, epochs=200, batch_size=32, shuffle=True, callbacks=[early_stopping], validation_data=(test_x, test_y))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.8986 - accuracy: 0.2956 - val_loss: 1.2286 - val_accuracy: 0.5461\n",
            "Epoch 2/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3037 - accuracy: 0.5388 - val_loss: 1.4452 - val_accuracy: 0.5027\n",
            "Epoch 3/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.0716 - accuracy: 0.6226 - val_loss: 1.0688 - val_accuracy: 0.6336\n",
            "Epoch 4/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9591 - accuracy: 0.6733 - val_loss: 0.8418 - val_accuracy: 0.7162\n",
            "Epoch 5/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8819 - accuracy: 0.6996 - val_loss: 0.8124 - val_accuracy: 0.7163\n",
            "Epoch 6/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8289 - accuracy: 0.7210 - val_loss: 0.7940 - val_accuracy: 0.7309\n",
            "Epoch 7/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7779 - accuracy: 0.7415 - val_loss: 0.7211 - val_accuracy: 0.7552\n",
            "Epoch 8/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7415 - accuracy: 0.7496 - val_loss: 0.6804 - val_accuracy: 0.7648\n",
            "Epoch 9/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7102 - accuracy: 0.7648 - val_loss: 0.5814 - val_accuracy: 0.8065\n",
            "Epoch 10/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6792 - accuracy: 0.7747 - val_loss: 0.5728 - val_accuracy: 0.8092\n",
            "Epoch 11/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6601 - accuracy: 0.7805 - val_loss: 0.7961 - val_accuracy: 0.7541\n",
            "Epoch 12/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6353 - accuracy: 0.7898 - val_loss: 0.5968 - val_accuracy: 0.8007\n",
            "Epoch 13/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6150 - accuracy: 0.8000 - val_loss: 0.6491 - val_accuracy: 0.7902\n",
            "Epoch 14/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5959 - accuracy: 0.8039 - val_loss: 0.6655 - val_accuracy: 0.7722\n",
            "Epoch 15/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5862 - accuracy: 0.8072 - val_loss: 0.5762 - val_accuracy: 0.8086\n",
            "Epoch 16/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5671 - accuracy: 0.8146 - val_loss: 0.6755 - val_accuracy: 0.7796\n",
            "Epoch 17/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5529 - accuracy: 0.8157 - val_loss: 0.5245 - val_accuracy: 0.8222\n",
            "Epoch 18/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5454 - accuracy: 0.8194 - val_loss: 0.5518 - val_accuracy: 0.8207\n",
            "Epoch 19/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5402 - accuracy: 0.8211 - val_loss: 0.5182 - val_accuracy: 0.8242\n",
            "Epoch 20/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5184 - accuracy: 0.8298 - val_loss: 0.5568 - val_accuracy: 0.8191\n",
            "Epoch 21/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5262 - accuracy: 0.8288 - val_loss: 0.4729 - val_accuracy: 0.8400\n",
            "Epoch 22/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5020 - accuracy: 0.8329 - val_loss: 0.4934 - val_accuracy: 0.8362\n",
            "Epoch 23/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4975 - accuracy: 0.8355 - val_loss: 0.4674 - val_accuracy: 0.8463\n",
            "Epoch 24/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4931 - accuracy: 0.8406 - val_loss: 0.5287 - val_accuracy: 0.8229\n",
            "Epoch 25/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4756 - accuracy: 0.8441 - val_loss: 0.5418 - val_accuracy: 0.8259\n",
            "Epoch 26/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4789 - accuracy: 0.8425 - val_loss: 0.4908 - val_accuracy: 0.8366\n",
            "Epoch 27/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4692 - accuracy: 0.8466 - val_loss: 0.6318 - val_accuracy: 0.8018\n",
            "Epoch 28/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4674 - accuracy: 0.8452 - val_loss: 0.4769 - val_accuracy: 0.8424\n",
            "Epoch 29/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4565 - accuracy: 0.8475 - val_loss: 0.5128 - val_accuracy: 0.8304\n",
            "Epoch 30/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4538 - accuracy: 0.8530 - val_loss: 0.5065 - val_accuracy: 0.8359\n",
            "Epoch 31/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4379 - accuracy: 0.8555 - val_loss: 0.4636 - val_accuracy: 0.8464\n",
            "Epoch 32/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4252 - accuracy: 0.8576 - val_loss: 0.5766 - val_accuracy: 0.8155\n",
            "Epoch 33/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4326 - accuracy: 0.8591 - val_loss: 0.4606 - val_accuracy: 0.8497\n",
            "Epoch 34/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4261 - accuracy: 0.8624 - val_loss: 0.4504 - val_accuracy: 0.8497\n",
            "Epoch 35/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4204 - accuracy: 0.8623 - val_loss: 0.5542 - val_accuracy: 0.8270\n",
            "Epoch 36/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4197 - accuracy: 0.8621 - val_loss: 0.5057 - val_accuracy: 0.8360\n",
            "Epoch 37/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4069 - accuracy: 0.8663 - val_loss: 0.5584 - val_accuracy: 0.8254\n",
            "Epoch 38/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4090 - accuracy: 0.8655 - val_loss: 0.4544 - val_accuracy: 0.8528\n",
            "Epoch 39/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4025 - accuracy: 0.8691 - val_loss: 0.4590 - val_accuracy: 0.8538\n",
            "Epoch 40/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4012 - accuracy: 0.8698 - val_loss: 0.5112 - val_accuracy: 0.8383\n",
            "Epoch 41/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3945 - accuracy: 0.8701 - val_loss: 0.4982 - val_accuracy: 0.8404\n",
            "Epoch 42/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3887 - accuracy: 0.8747 - val_loss: 0.4473 - val_accuracy: 0.8536\n",
            "Epoch 43/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3909 - accuracy: 0.8713 - val_loss: 0.4599 - val_accuracy: 0.8505\n",
            "Epoch 44/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3870 - accuracy: 0.8704 - val_loss: 0.4642 - val_accuracy: 0.8544\n",
            "Epoch 45/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3897 - accuracy: 0.8724 - val_loss: 0.4585 - val_accuracy: 0.8526\n",
            "Epoch 46/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3738 - accuracy: 0.8774 - val_loss: 0.4575 - val_accuracy: 0.8505\n",
            "Epoch 47/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3679 - accuracy: 0.8788 - val_loss: 0.5177 - val_accuracy: 0.8405\n",
            "Epoch 48/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3665 - accuracy: 0.8798 - val_loss: 0.4334 - val_accuracy: 0.8610\n",
            "Epoch 49/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3600 - accuracy: 0.8821 - val_loss: 0.4804 - val_accuracy: 0.8503\n",
            "Epoch 50/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3600 - accuracy: 0.8813 - val_loss: 0.4420 - val_accuracy: 0.8610\n",
            "Epoch 51/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3547 - accuracy: 0.8844 - val_loss: 0.4858 - val_accuracy: 0.8518\n",
            "Epoch 52/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3549 - accuracy: 0.8846 - val_loss: 0.4556 - val_accuracy: 0.8526\n",
            "Epoch 53/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3602 - accuracy: 0.8839 - val_loss: 0.4669 - val_accuracy: 0.8484\n",
            "Epoch 54/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3497 - accuracy: 0.8855 - val_loss: 0.4545 - val_accuracy: 0.8588\n",
            "Epoch 55/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3370 - accuracy: 0.8891 - val_loss: 0.5182 - val_accuracy: 0.8446\n",
            "Epoch 56/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3471 - accuracy: 0.8881 - val_loss: 0.4669 - val_accuracy: 0.8515\n",
            "Epoch 57/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3501 - accuracy: 0.8851 - val_loss: 0.5038 - val_accuracy: 0.8405\n",
            "Epoch 58/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3399 - accuracy: 0.8878 - val_loss: 0.4735 - val_accuracy: 0.8573\n",
            "Epoch 59/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3400 - accuracy: 0.8872 - val_loss: 0.4507 - val_accuracy: 0.8592\n",
            "Epoch 60/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3363 - accuracy: 0.8892 - val_loss: 0.4543 - val_accuracy: 0.8561\n",
            "Epoch 61/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3372 - accuracy: 0.8908 - val_loss: 0.4673 - val_accuracy: 0.8563\n",
            "Epoch 62/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3363 - accuracy: 0.8923 - val_loss: 0.5076 - val_accuracy: 0.8475\n",
            "Epoch 63/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3287 - accuracy: 0.8925 - val_loss: 0.4366 - val_accuracy: 0.8609\n",
            "Epoch 64/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3190 - accuracy: 0.8943 - val_loss: 0.4567 - val_accuracy: 0.8586\n",
            "Epoch 65/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3311 - accuracy: 0.8909 - val_loss: 0.4629 - val_accuracy: 0.8585\n",
            "Epoch 66/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3187 - accuracy: 0.8945 - val_loss: 0.4460 - val_accuracy: 0.8618\n",
            "Epoch 67/200\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3256 - accuracy: 0.8920 - val_loss: 0.4632 - val_accuracy: 0.8621\n",
            "Epoch 68/200\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3173 - accuracy: 0.8952 - val_loss: 0.4999 - val_accuracy: 0.8492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeJwx777swlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a381870a-dd71-4a23-89ef-d38a73a66556"
      },
      "source": [
        "loss, acc = model.evaluate(test_x, test_y, verbose = 2)\n",
        "print(acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.4334 - accuracy: 0.8610\n",
            "0.8610000014305115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJHvWzEgswlx"
      },
      "source": [
        "# Used websites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-1NEgSCswlx"
      },
      "source": [
        "https://www.tensorflow.org/tutorials/images/cnn\n",
        "https://www.tensorflow.org/addons/tutorials/layers_normalizations\n",
        "https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/\n",
        "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/Model"
      ]
    }
  ]
}