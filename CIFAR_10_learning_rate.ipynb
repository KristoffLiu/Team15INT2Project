{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR_10_learning_rate.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ0wBuXCswlo"
      },
      "source": [
        "# Downloading and preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyR4qrFMswlq"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1pRAKp0swls"
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = datasets.cifar10.load_data()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cA0nUAVswlt"
      },
      "source": [
        "train_x, test_x = train_x / 255.0, test_x / 255.0 #changes pixel values between 0 and 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr-igcfXswlt"
      },
      "source": [
        "# Improving the Basic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnVT4on7swlu",
        "outputId": "1afc5c92-1f3b-43b4-b323-28c901df761a"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001), input_shape=(32,32,3)))#creates layers for a 2d array of pixels\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64,(3,3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2))) #pooling helps detect features in an image, max pooling finds largest value\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv2D(128,(3,3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128,(3,3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv2D(256,(3,3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(256,(3,3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.0001), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation = 'relu'))#regularisation of data\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_66 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_67 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_68 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,675,210\n",
            "Trainable params: 1,673,162\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWko6DFAswlw"
      },
      "source": [
        "\n",
        "\n",
        "# Running, training, and evaluating data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlVi9t-eswlw",
        "outputId": "a2ee0344-bb86-4f0a-d5e4-042b3e3776a3"
      },
      "source": [
        "model.compile(optimizer='RMSprop',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "batch = 512\n",
        "#create iterator - training data\n",
        "it_train = datagen.flow(train_x, tf.squeeze(train_y), batch_size = batch) #batch_size default= 32\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 70:\n",
        "    return lr\n",
        "  if epoch < 90:\n",
        "    return lr * tf.math.exp(-0.3)\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "\n",
        "\n",
        "learning_rate_scheduling = LearningRateScheduler(scheduler)\n",
        "\n",
        "progress = model.fit(it_train, epochs=200, batch_size=batch, shuffle=True, callbacks=[early_stopping, learning_rate_scheduling], validation_data=(test_x, test_y))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "98/98 [==============================] - 25s 238ms/step - loss: 2.3788 - accuracy: 0.2971 - val_loss: 3.1614 - val_accuracy: 0.1000\n",
            "Epoch 2/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 1.4301 - accuracy: 0.5339 - val_loss: 2.6621 - val_accuracy: 0.1411\n",
            "Epoch 3/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 1.1015 - accuracy: 0.6515 - val_loss: 2.5684 - val_accuracy: 0.1882\n",
            "Epoch 4/200\n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.9256 - accuracy: 0.7105 - val_loss: 2.1277 - val_accuracy: 0.3509\n",
            "Epoch 5/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.8191 - accuracy: 0.7512 - val_loss: 1.3486 - val_accuracy: 0.5689\n",
            "Epoch 6/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.7604 - accuracy: 0.7751 - val_loss: 0.9477 - val_accuracy: 0.7094\n",
            "Epoch 7/200\n",
            "98/98 [==============================] - 23s 237ms/step - loss: 0.7155 - accuracy: 0.7902 - val_loss: 0.7745 - val_accuracy: 0.7787\n",
            "Epoch 8/200\n",
            "98/98 [==============================] - 23s 237ms/step - loss: 0.6653 - accuracy: 0.8084 - val_loss: 0.8478 - val_accuracy: 0.7590\n",
            "Epoch 9/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.6380 - accuracy: 0.8196 - val_loss: 0.7369 - val_accuracy: 0.7974\n",
            "Epoch 10/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.6137 - accuracy: 0.8306 - val_loss: 0.8278 - val_accuracy: 0.7836\n",
            "Epoch 11/200\n",
            "98/98 [==============================] - 23s 238ms/step - loss: 0.5911 - accuracy: 0.8395 - val_loss: 0.6355 - val_accuracy: 0.8236\n",
            "Epoch 12/200\n",
            "98/98 [==============================] - 23s 237ms/step - loss: 0.5607 - accuracy: 0.8519 - val_loss: 0.8193 - val_accuracy: 0.7832\n",
            "Epoch 13/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.5539 - accuracy: 0.8542 - val_loss: 0.6186 - val_accuracy: 0.8394\n",
            "Epoch 14/200\n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.5326 - accuracy: 0.8651 - val_loss: 0.6406 - val_accuracy: 0.8407\n",
            "Epoch 15/200\n",
            "98/98 [==============================] - 23s 237ms/step - loss: 0.5237 - accuracy: 0.8677 - val_loss: 0.8566 - val_accuracy: 0.7818\n",
            "Epoch 16/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.5191 - accuracy: 0.8690 - val_loss: 0.6374 - val_accuracy: 0.8360\n",
            "Epoch 17/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.5013 - accuracy: 0.8783 - val_loss: 0.5947 - val_accuracy: 0.8515\n",
            "Epoch 18/200\n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.5043 - accuracy: 0.8780 - val_loss: 0.5687 - val_accuracy: 0.8629\n",
            "Epoch 19/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4964 - accuracy: 0.8789 - val_loss: 0.6535 - val_accuracy: 0.8427\n",
            "Epoch 20/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4836 - accuracy: 0.8857 - val_loss: 0.5970 - val_accuracy: 0.8578\n",
            "Epoch 21/200\n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.4743 - accuracy: 0.8873 - val_loss: 0.6089 - val_accuracy: 0.8572\n",
            "Epoch 22/200\n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.4682 - accuracy: 0.8906 - val_loss: 0.6315 - val_accuracy: 0.8475\n",
            "Epoch 23/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4624 - accuracy: 0.8958 - val_loss: 0.5679 - val_accuracy: 0.8702\n",
            "Epoch 24/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4582 - accuracy: 0.8965 - val_loss: 0.5931 - val_accuracy: 0.8631\n",
            "Epoch 25/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4555 - accuracy: 0.8975 - val_loss: 0.5858 - val_accuracy: 0.8670\n",
            "Epoch 26/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4527 - accuracy: 0.9015 - val_loss: 0.6654 - val_accuracy: 0.8446\n",
            "Epoch 27/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4472 - accuracy: 0.9027 - val_loss: 0.6009 - val_accuracy: 0.8614\n",
            "Epoch 28/200\n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.4480 - accuracy: 0.9014 - val_loss: 0.5726 - val_accuracy: 0.8685\n",
            "Epoch 29/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4432 - accuracy: 0.9052 - val_loss: 0.7149 - val_accuracy: 0.8284\n",
            "Epoch 30/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4350 - accuracy: 0.9085 - val_loss: 0.6741 - val_accuracy: 0.8427\n",
            "Epoch 31/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4372 - accuracy: 0.9077 - val_loss: 0.5605 - val_accuracy: 0.8768\n",
            "Epoch 32/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4248 - accuracy: 0.9142 - val_loss: 0.5565 - val_accuracy: 0.8780\n",
            "Epoch 33/200\n",
            "98/98 [==============================] - 23s 236ms/step - loss: 0.4228 - accuracy: 0.9126 - val_loss: 0.5764 - val_accuracy: 0.8705\n",
            "Epoch 34/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4187 - accuracy: 0.9143 - val_loss: 0.6443 - val_accuracy: 0.8543\n",
            "Epoch 35/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4231 - accuracy: 0.9129 - val_loss: 0.5493 - val_accuracy: 0.8801\n",
            "Epoch 36/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4148 - accuracy: 0.9165 - val_loss: 0.6080 - val_accuracy: 0.8703\n",
            "Epoch 37/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4163 - accuracy: 0.9166 - val_loss: 0.5125 - val_accuracy: 0.8916\n",
            "Epoch 38/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4165 - accuracy: 0.9155 - val_loss: 0.6461 - val_accuracy: 0.8559\n",
            "Epoch 39/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4138 - accuracy: 0.9190 - val_loss: 0.5751 - val_accuracy: 0.8765\n",
            "Epoch 40/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4208 - accuracy: 0.9169 - val_loss: 0.5312 - val_accuracy: 0.8894\n",
            "Epoch 41/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4129 - accuracy: 0.9160 - val_loss: 0.5604 - val_accuracy: 0.8821\n",
            "Epoch 42/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4105 - accuracy: 0.9209 - val_loss: 0.6048 - val_accuracy: 0.8743\n",
            "Epoch 43/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4121 - accuracy: 0.9206 - val_loss: 0.5319 - val_accuracy: 0.8910\n",
            "Epoch 44/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4037 - accuracy: 0.9236 - val_loss: 0.5338 - val_accuracy: 0.8888\n",
            "Epoch 45/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4061 - accuracy: 0.9236 - val_loss: 0.5914 - val_accuracy: 0.8742\n",
            "Epoch 46/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.4033 - accuracy: 0.9235 - val_loss: 0.5647 - val_accuracy: 0.8840\n",
            "Epoch 47/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4039 - accuracy: 0.9224 - val_loss: 0.5990 - val_accuracy: 0.8750\n",
            "Epoch 48/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4063 - accuracy: 0.9239 - val_loss: 0.6247 - val_accuracy: 0.8659\n",
            "Epoch 49/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.4055 - accuracy: 0.9232 - val_loss: 0.6222 - val_accuracy: 0.8729\n",
            "Epoch 50/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.3988 - accuracy: 0.9269 - val_loss: 0.6281 - val_accuracy: 0.8709\n",
            "Epoch 51/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3994 - accuracy: 0.9255 - val_loss: 0.8303 - val_accuracy: 0.8216\n",
            "Epoch 52/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3947 - accuracy: 0.9276 - val_loss: 0.6605 - val_accuracy: 0.8689\n",
            "Epoch 53/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.3923 - accuracy: 0.9281 - val_loss: 0.5409 - val_accuracy: 0.8930\n",
            "Epoch 54/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.4014 - accuracy: 0.9247 - val_loss: 0.5773 - val_accuracy: 0.8881\n",
            "Epoch 55/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3949 - accuracy: 0.9281 - val_loss: 0.5294 - val_accuracy: 0.8980\n",
            "Epoch 56/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.3905 - accuracy: 0.9299 - val_loss: 0.5217 - val_accuracy: 0.8981\n",
            "Epoch 57/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.3864 - accuracy: 0.9318 - val_loss: 0.5874 - val_accuracy: 0.8838\n",
            "Epoch 58/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.3859 - accuracy: 0.9333 - val_loss: 0.6087 - val_accuracy: 0.8758\n",
            "Epoch 59/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3830 - accuracy: 0.9340 - val_loss: 0.5543 - val_accuracy: 0.8934\n",
            "Epoch 60/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.3883 - accuracy: 0.9319 - val_loss: 0.6091 - val_accuracy: 0.8736\n",
            "Epoch 61/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.3842 - accuracy: 0.9327 - val_loss: 0.5381 - val_accuracy: 0.8917\n",
            "Epoch 62/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3950 - accuracy: 0.9310 - val_loss: 0.6141 - val_accuracy: 0.8779\n",
            "Epoch 63/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.3785 - accuracy: 0.9339 - val_loss: 0.5662 - val_accuracy: 0.8878\n",
            "Epoch 64/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.3870 - accuracy: 0.9314 - val_loss: 0.5720 - val_accuracy: 0.8857\n",
            "Epoch 65/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.3842 - accuracy: 0.9324 - val_loss: 0.6602 - val_accuracy: 0.8685\n",
            "Epoch 66/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.3856 - accuracy: 0.9345 - val_loss: 0.5801 - val_accuracy: 0.8865\n",
            "Epoch 67/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3789 - accuracy: 0.9352 - val_loss: 0.5622 - val_accuracy: 0.8916\n",
            "Epoch 68/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.3811 - accuracy: 0.9357 - val_loss: 0.5992 - val_accuracy: 0.8813\n",
            "Epoch 69/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.3823 - accuracy: 0.9341 - val_loss: 0.5792 - val_accuracy: 0.8871\n",
            "Epoch 70/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.3817 - accuracy: 0.9350 - val_loss: 0.6620 - val_accuracy: 0.8672\n",
            "Epoch 71/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3669 - accuracy: 0.9389 - val_loss: 0.5514 - val_accuracy: 0.8926\n",
            "Epoch 72/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3435 - accuracy: 0.9471 - val_loss: 0.4996 - val_accuracy: 0.9058\n",
            "Epoch 73/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.3178 - accuracy: 0.9551 - val_loss: 0.4658 - val_accuracy: 0.9149\n",
            "Epoch 74/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.3119 - accuracy: 0.9572 - val_loss: 0.4908 - val_accuracy: 0.9109\n",
            "Epoch 75/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.2980 - accuracy: 0.9608 - val_loss: 0.4835 - val_accuracy: 0.9150\n",
            "Epoch 76/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2872 - accuracy: 0.9642 - val_loss: 0.4662 - val_accuracy: 0.9174\n",
            "Epoch 77/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2789 - accuracy: 0.9650 - val_loss: 0.4734 - val_accuracy: 0.9149\n",
            "Epoch 78/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2781 - accuracy: 0.9661 - val_loss: 0.4653 - val_accuracy: 0.9184\n",
            "Epoch 79/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2746 - accuracy: 0.9665 - val_loss: 0.4618 - val_accuracy: 0.9177\n",
            "Epoch 80/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2716 - accuracy: 0.9682 - val_loss: 0.4605 - val_accuracy: 0.9197\n",
            "Epoch 81/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2660 - accuracy: 0.9689 - val_loss: 0.4601 - val_accuracy: 0.9206\n",
            "Epoch 82/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2668 - accuracy: 0.9705 - val_loss: 0.4605 - val_accuracy: 0.9221\n",
            "Epoch 83/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.2646 - accuracy: 0.9708 - val_loss: 0.4611 - val_accuracy: 0.9219\n",
            "Epoch 84/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2674 - accuracy: 0.9687 - val_loss: 0.4611 - val_accuracy: 0.9206\n",
            "Epoch 85/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2660 - accuracy: 0.9697 - val_loss: 0.4613 - val_accuracy: 0.9210\n",
            "Epoch 86/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2612 - accuracy: 0.9707 - val_loss: 0.4609 - val_accuracy: 0.9207\n",
            "Epoch 87/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.2623 - accuracy: 0.9707 - val_loss: 0.4610 - val_accuracy: 0.9206\n",
            "Epoch 88/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2623 - accuracy: 0.9711 - val_loss: 0.4594 - val_accuracy: 0.9213\n",
            "Epoch 89/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2631 - accuracy: 0.9712 - val_loss: 0.4599 - val_accuracy: 0.9211\n",
            "Epoch 90/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.2612 - accuracy: 0.9715 - val_loss: 0.4601 - val_accuracy: 0.9211\n",
            "Epoch 91/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.2594 - accuracy: 0.9726 - val_loss: 0.4597 - val_accuracy: 0.9213\n",
            "Epoch 92/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2601 - accuracy: 0.9711 - val_loss: 0.4603 - val_accuracy: 0.9207\n",
            "Epoch 93/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2605 - accuracy: 0.9717 - val_loss: 0.4601 - val_accuracy: 0.9208\n",
            "Epoch 94/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2668 - accuracy: 0.9682 - val_loss: 0.4604 - val_accuracy: 0.9205\n",
            "Epoch 95/200\n",
            "98/98 [==============================] - 23s 232ms/step - loss: 0.2617 - accuracy: 0.9704 - val_loss: 0.4603 - val_accuracy: 0.9209\n",
            "Epoch 96/200\n",
            "98/98 [==============================] - 23s 235ms/step - loss: 0.2609 - accuracy: 0.9709 - val_loss: 0.4598 - val_accuracy: 0.9207\n",
            "Epoch 97/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2642 - accuracy: 0.9696 - val_loss: 0.4598 - val_accuracy: 0.9207\n",
            "Epoch 98/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2598 - accuracy: 0.9717 - val_loss: 0.4598 - val_accuracy: 0.9209\n",
            "Epoch 99/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2636 - accuracy: 0.9699 - val_loss: 0.4596 - val_accuracy: 0.9209\n",
            "Epoch 100/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2618 - accuracy: 0.9712 - val_loss: 0.4596 - val_accuracy: 0.9211\n",
            "Epoch 101/200\n",
            "98/98 [==============================] - 23s 233ms/step - loss: 0.2596 - accuracy: 0.9716 - val_loss: 0.4597 - val_accuracy: 0.9207\n",
            "Epoch 102/200\n",
            "98/98 [==============================] - 23s 234ms/step - loss: 0.2647 - accuracy: 0.9687 - val_loss: 0.4598 - val_accuracy: 0.9210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeJwx777swlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee752d5-5c7d-4263-8fc1-e7be7d193951"
      },
      "source": [
        "loss, acc = model.evaluate(test_x, test_y, verbose = 2)\n",
        "print(acc)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.4605 - accuracy: 0.9221\n",
            "0.9221000075340271\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}